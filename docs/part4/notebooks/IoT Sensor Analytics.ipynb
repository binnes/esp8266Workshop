{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pixiedust\n",
    "import pixiedust\n",
    "pixiedust.installPackage(\"org.apache.bahir:spark-sql-cloudant_2.11:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO Please provide your Cloudant credentials in this cell\n",
    "def readDataFrameFromCloudant(database):\n",
    "\n",
    "  cloudantdata = spark.read.format(\"org.apache.bahir.cloudant\")\\\n",
    "    .option(\"cloudant.host\",'XXXX-bluemix.cloudant.com')\\\n",
    "    .option(\"cloudant.username\", 'XXXX-bluemix')\\\n",
    "    .option(\"cloudant.password\",'XXXX')\\\n",
    "    .load(database)\n",
    "    \n",
    "  return cloudantdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=readDataFrameFromCloudant('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable SQL on the data frame\n",
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import translate, col\n",
    "\n",
    "df_cleaned = df \\\n",
    "    .withColumn(\"temp\", df.tmp.cast('double')) \\\n",
    "    .withColumn(\"humidity\", df.hmdty.cast('double')) \\\n",
    "\n",
    "df_cleaned.createOrReplaceTempView('df_cleaned')\n",
    "df_cleaned.select('tmp', 'hmdty').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0 = spark.sql('select time, tmp, hmdty, class from df_cleaned where class = 0')\n",
    "df_class_1 = spark.sql('select time, tmp, hmdty, class from df_cleaned where class = 1')\n",
    "df_class_0.createOrReplaceTempView('df_class_0')\n",
    "df_class_1.createOrReplaceTempView('df_class_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1.select('tmp', 'hmdty').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0.select('tmp', 'hmdty').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('select class, count(class) from df_cleaned group by class').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(df_class_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for modelling\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary classifier model\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"humidity\",\"temp\"],\n",
    "                                  outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=1000).setLabelCol(\"class\")\n",
    "pipeline = Pipeline(stages=[vectorAssembler, lr ])\n",
    "model = pipeline.fit(df_cleaned)\n",
    "result = model.transform(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stages[1].coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stages[1].intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    }
   },
   "outputs": [],
   "source": [
    "#evaluate classification accuracy (1.0 = 100% accurate)\n",
    "binEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\").setPredictionCol(\"prediction\").setLabelCol(\"class\")    \n",
    "binEval.evaluate(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "# re-read data from cloudant\n",
    "new_df = readDataFrameFromCloudant('training')\n",
    "new_df_cleaned = new_df \\\n",
    "    .withColumn(\"temp\", new_df.tmp.cast('double')) \\\n",
    "    .withColumn(\"hmdty\", new_df.hmdty.cast('double')) \\\n",
    "\n",
    "new_df_cleaned.createOrReplaceTempView('df_cleaned')\n",
    "\n",
    "result = model.transform(new_df_cleaned)\n",
    "result.createOrReplaceTempView('result')\n",
    "spark.sql(\"select hmdty, tmp, class, prediction from result\").show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 with Spark",
   "language": "python3",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}